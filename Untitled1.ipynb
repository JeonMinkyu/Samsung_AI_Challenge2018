{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import json\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "train_data = pd.read_csv('C:/Users/good/Desktop/Samsung_Train.csv')\n",
    "test_data = pd.read_csv('C:/Users/good/Desktop/test_kor.csv')\n",
    "\n",
    "train_data = train_data.dropna() #결측값 행 제거\n",
    "col_list = ['주야','요일','사망자수','사상자수','중상자수','경상자수','부상신고자수','발생지시도','발생지시군구','사고유형_대분류','사고유형_중분류','법규위반','도로형태_대분류','도로형태','당사자종별_1당_대분류','당사자종별_2당_대분류']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "\n",
    "def official_numerical_score(pred, real, B=1, s=1):\n",
    "    return B*sum([exp(-((n-m)/2)**2) for n,m in zip(pred, real)])\n",
    "\n",
    "def official_categorical_score(pred, real, C=1):\n",
    "    return C*sum([1 if ci==di else 0 for ci, di in zip(pred, real)])\n",
    "\n",
    "def refine_val(df, target_col, dependent_col_list):\n",
    "    for t_col in col_list:\n",
    "        df=df[[isinstance(x,float) and np.isnan(x) for x in df[t_col]]]\n",
    "    for d_col in dependent_col_list:\n",
    "        df=df[[not (isinstance(x, float) and np.isnan(x)) for x in df[d_col]]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def preprocessing(data):\n",
    "    onehot_col=[]\n",
    "    \n",
    "    for col in data.columns:\n",
    "        if isinstance(data[col].values[0], str):\n",
    "            onehot_col.append(col)\n",
    "            \n",
    "    data=pd.get_dummies(data, prefix=onehot_col)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRegModel:\n",
    "    def __init__(self):\n",
    "        self.model = RandomForestRegressor(n_estimators=20, max_depth=5, random_state=1000)\n",
    "    def train(self, X, y, params=None):\n",
    "        if params is not None:\n",
    "            self.model_tmp=self.model\n",
    "            self.model = GridSearchCV(self.model_tmp, params, cv=5, scoring=make_scorer(official_numerical_score,\n",
    "                                                                                       greater_is_better=True,\n",
    "                                                                                       needs_proba=False))\n",
    "            self.model.fit(X,y)\n",
    "    def predict(self, X):\n",
    "        self.predReal = self.model.predict(X)\n",
    "        self.pred=[round(x) for x in self.predReal]\n",
    "        return self.pred\n",
    "    def evaluation(self, test_y, pred):\n",
    "        self.ev={}\n",
    "        self.ev['MSE'] = mean_squared_error(test_y, pred)\n",
    "        self.ev['Official Numerical Score'] = official_numerical_score(test_y, pred)\n",
    "        return self.ev\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomClfModel:\n",
    "    def __init__(self):\n",
    "        self.model=RandomForestClassifier(n_estimators=20, max_depth=5, random_State=1000)\n",
    "    def train(self, X, y, params=None):\n",
    "        if params is not None:\n",
    "            self.model_tmp=self.model\n",
    "            self.model = GridSearchCV(self.model_tmp, params, cv=5, scoring=make_scorer(official_categorical_score, greater_is_better=True,\n",
    "                                                                                       needs_proba=False))\n",
    "        self.model.fit(X,y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        self.pred = self.model.predict(X)\n",
    "        return self.pred\n",
    "    def evaluation(self, test_y, pred):\n",
    "        self.ev={}\n",
    "        self.ev['ACC'] = accuracy_score(test_y, pred)\n",
    "        self.ev['Official Categorical Score'] = official_categorical_score(test_y, pred)\n",
    "        return self.ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# main\n",
    "model_meta_dict = {}\n",
    "col_record = {}\n",
    "\n",
    "for _, row in test_data.iterrows():\n",
    "    col_list = []\n",
    "    dependent_col_list = []\n",
    "    for key, value in row.items():\n",
    "        if isinstance(value, float) and np.isnan(value):\n",
    "            col_list.append(key)\n",
    "        else:\n",
    "            dependent_col_list.append(key)\n",
    "    \n",
    "    for t_col in col_list:\n",
    "        col_key = t_col + ':' + '/'.join(dependent_col_list)\n",
    "        if col_record.get(col_key):\n",
    "            continue\n",
    "        model_dict = {}\n",
    "        model_dict['target_col'] = t_col\n",
    "        model_dict['dependent_col_list'] = dependent_col_list\n",
    "\n",
    "        if train_data is not None:\n",
    "            tmp_test_data = test_data.copy()\n",
    "            tmp_test_data = refine_val(tmp_test_data, col_list, dependent_col_list)\n",
    "            model_dict['train_data_loc'] = tmp_test_data.index\n",
    "    \n",
    "        model_meta_dict[col_key] = model_dict\n",
    "        col_record[col_key] = 1\n",
    "\n",
    "save_dict = {}\n",
    "loss_all_val1 = 0\n",
    "if train_data is not None:\n",
    "    loss_all_val2 = 0\n",
    "\n",
    "tuned_parameters = {'n_estimators' : [3, 10, 30, 100, 300, 1000]}\n",
    "\n",
    "#tuned_parameters = None\n",
    "\n",
    "\n",
    "for i, model_dict_key in enumerate(model_meta_dict):\n",
    "    data = ori_data.copy()\n",
    "    model_dict = model_meta_dict[model_dict_key]\n",
    "    target_col = model_dict['target_col']\n",
    "    dependent_col_list = model_dict['dependent_col_list']\n",
    "    if train_data is not None:\n",
    "        tmp_val_data = train_data.iloc[model_dict['train_data_loc']]\n",
    "    result = {\n",
    "        'target_col' : target_col,\n",
    "        'dependent_col' : dependent_col_list\n",
    "    }\n",
    "    print(str(i+1) + '/' + str(len(model_meta_dict)))\n",
    "    print('key : ', model_dict_key)\n",
    "    print('loc : ', model_dict['train_data_loc'].values)\n",
    "    print('tar_col : ', target_col)\n",
    "    print('dep_col : ', dependent_col_list)\n",
    "\n",
    "    data['val'] = 0\n",
    "\n",
    "    if tmp_val_data is not None:\n",
    "        tmp_val_data['val'] = 1\n",
    "        data = data.append(tmp_val_data)\n",
    "\n",
    "    X = data[dependent_col_list + ['val']]\n",
    "    y = data[[target_col, 'val']]\n",
    "\n",
    "    X = preprocessing(X)\n",
    "\n",
    "    if tmp_val_data is not None:\n",
    "        val_X = X[X['val'] == 1]\n",
    "        val_y = y[y['val'] == 1]\n",
    "        X = X[X['val'] == 0]\n",
    "        y = y[y['val'] == 0]\n",
    "\n",
    "        val_X = val_X.drop(['val'], axis=1)\n",
    "        val_y = val_y[target_col].values\n",
    "\n",
    "    X = X.drop(['val'], axis=1)\n",
    "    y = y[target_col].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=RANDOM_SEED)\n",
    "    \n",
    "    if isinstance(y_test[0], str): # clf\n",
    "        model = CustomClfModel()\n",
    "    else:\n",
    "        model = CustomRegModel()\n",
    "    model.train(X_train, y_train, tuned_parameters)\n",
    "    print('best parameter : ', model.model.best_params_)\n",
    "    pred = model.predict(X_test)\n",
    "    val_eval = model.evaluation(pred, y_test)\n",
    "    print('val1 : ', val_eval)\n",
    "    result['val_1'] = val_eval\n",
    "    loss_all_val1 = val_eval\n",
    "\n",
    "    if tmp_val_data is not None:\n",
    "        val_pred = model.predict(val_X)\n",
    "        val_eval = model.evaluation(val_pred, val_y)\n",
    "        print('val2 : ', val_eval)\n",
    "        result['val_2'] = val_eval\n",
    "        official_score_key = [v for v in val_eval if 'Official' in v][0]\n",
    "        loss_all_val2 += val_eval[official_score_key]\n",
    "        print('val2 shape : ', tmp_val_data.shape)\n",
    "\n",
    "    print()\n",
    "    save_dict[i] = result\n",
    "    \n",
    "    model_meta_dict[model_dict_key]['model'] = model\n",
    "\n",
    "save_dict['loss_all_val1'] = loss_all_val1\n",
    "save_dict['loss_all_val2'] = loss_all_val2\n",
    "\n",
    "now_string = str(datetime.datetime.now())\n",
    "now_string = now_string.replace(':', '-')\n",
    "now_string = str(round(loss_all_val2, 4)).zfill(8) + ' ' + now_string\n",
    "with open('result/' + now_string + '.json', 'w') as f:\n",
    "    json.dump(save_dict, f)\n",
    "with open('result/' + now_string + '.p', 'wb') as f:\n",
    "    pickle.dump(model_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
